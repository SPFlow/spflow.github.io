<!doctype html>
<html class="no-js" lang="en" data-content_root="../">
  <head><meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../genindex.html"><link rel="search" title="Search" href="../search.html"><link rel="next" title="Developer Guide" href="dev_guide.html"><link rel="prev" title="Getting Started" href="../getting_started.html">

    <!-- Generated with Sphinx 8.2.3 and Furo 2025.12.19 -->
        <title>User Guide - SPFlow 1.0.0</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=d111a655" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=7bdb33bb" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/nbsphinx-code-cells.css?v=2aa19091" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=8dab3a3b" />
    
    


<style>
  body {
    --color-code-background: #f2f2f2;
  --color-code-foreground: #1e1e1e;
  --color-brand-primary: #0066cc;
  --color-brand-content: #0066cc;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  --color-brand-primary: #4da6ff;
  --color-brand-content: #4da6ff;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  --color-brand-primary: #4da6ff;
  --color-brand-content: #4da6ff;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle site navigation sidebar">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc" aria-label="Toggle table of contents sidebar">
<label class="overlay sidebar-overlay" for="__navigation"></label>
<label class="overlay toc-overlay" for="__toc"></label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <span class="icon"><svg><use href="#svg-menu"></use></svg></span>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">SPFlow 1.0.0</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle" aria-label="Toggle Light / Dark / Auto color theme">
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <span class="icon"><svg><use href="#svg-toc"></use></svg></span>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  <span class="sidebar-brand-text">SPFlow 1.0.0</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../getting_started.html">Getting Started</a></li>
<li class="toctree-l1 current current-page"><a class="current reference internal" href="#">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="dev_guide.html">Developer Guide</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api/index.html">API Documentation</a><input aria-label="Toggle navigation of API Documentation" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../api/base_modules.html">Base Classes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/module_shape.html">Module Shape</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/sums.html">Sum Modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/products.html">Product Modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/conv.html">Convolutional Modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/einsum.html">Einsum Modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/leaves.html">Leaf Modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/operations.html">Operations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/rat_spn.html">RAT-SPN Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/learning.html">Learning and Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/scope.html">Scope Management</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/utilities.html">Utilities</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/wrappers.html">Wrapper Modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/interfaces.html">Interfaces</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/exceptions.html">Exceptions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">Frequently Asked Questions</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="../_sources/guides/user_guide.ipynb.txt" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle" aria-label="Toggle Light / Dark / Auto color theme">
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <span class="icon"><svg><use href="#svg-toc"></use></svg></span>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="User-Guide">
<h1>User Guide<a class="headerlink" href="#User-Guide" title="Link to this heading">¶</a></h1>
<p>SPFlow is an open-source functional-oriented Python package for Probabilistic Circuits (PCs) with ready-to-use implementations for Sum-Product Networks (SPNs). PCs are a class of powerful deep probabilistic models - expressible as directed acyclic graphs - that allow for tractable querying. This library provides routines for creating, learning, manipulating and interacting with PCs and is highly extensible and customizable.</p>
<section id="Create-Toy-Dataset">
<h2>Create Toy Dataset<a class="headerlink" href="#Create-Toy-Dataset" title="Link to this heading">¶</a></h2>
<p>To demonstrate and visualize the main features of the library, we first create a 2D toy dataset with three Gaussian clusters, corresponding to labels 0, 1, and 2. The dataset is created with an imbalance. Therefore, class 0 has 200 datapoints, class 1 400 datapoints and class 2 600 datapoints, for a total of 1,200 data points.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="c1"># --- 1. Define the parameters for our dataset ---</span>

<span class="n">n_points_per_cluster</span> <span class="o">=</span> <span class="mi">200</span>

<span class="n">means</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span>
    <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">],</span>  <span class="c1"># Cluster 0</span>
    <span class="p">[</span><span class="o">-</span><span class="mf">3.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.0</span><span class="p">],</span>  <span class="c1"># Cluster 1</span>
    <span class="p">[</span><span class="mf">3.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.0</span><span class="p">]</span>  <span class="c1"># Cluster 2</span>
<span class="p">])</span>

<span class="n">stds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span>
    <span class="p">[</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]</span>
<span class="p">])</span>

<span class="c1"># --- 2. Generate the data and labels ---</span>

<span class="n">all_clusters</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">all_labels</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">means</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_points_per_cluster</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">stds</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">+</span> <span class="n">means</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">n_points_per_cluster</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),),</span> <span class="n">i</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>  <span class="c1"># label = cluster index</span>
    <span class="n">all_clusters</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
    <span class="n">all_labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>

<span class="c1"># Concatenate all data and labels</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">all_clusters</span><span class="p">)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">all_labels</span><span class="p">)</span>

<span class="c1"># --- 3. Shuffle dataset and labels together ---</span>

<span class="n">shuffled_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="n">shuffled_indices</span><span class="p">]</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="n">shuffled_indices</span><span class="p">]</span>

<span class="c1"># --- 4. Display some info ---</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Dataset successfully created.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Shape of dataset: </span><span class="si">{</span><span class="n">dataset</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Shape of labels: </span><span class="si">{</span><span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;First 5 samples:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dataset</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Corresponding labels:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">labels</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>

<span class="c1"># --- 5. Visualize the labeled dataset ---</span>

<span class="n">data_np</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">labels_np</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>


<span class="k">def</span><span class="w"> </span><span class="nf">plot_scatter</span><span class="p">(</span><span class="n">data_list</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">label_list</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;blue&quot;</span><span class="p">,</span> <span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="s2">&quot;yellow&quot;</span><span class="p">,</span> <span class="s2">&quot;green&quot;</span><span class="p">]</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data_list</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data_list</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">label_list</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_list</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">data</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">data</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;viridis&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Cluster Label&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">data</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">data</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label_list</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Feature 1 (x-axis)&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Feature 2 (y-axis)&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">)</span>
    <span class="c1">#plt.colorbar(label=&#39;Cluster Label&#39;)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="n">plot_scatter</span><span class="p">([</span><span class="n">data_np</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Generated 2D Toy Dataset (with Labels)&#39;</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels_np</span><span class="p">,</span> <span class="n">label_list</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Toy Data&#39;</span><span class="p">])</span>
<br/><br/></pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Dataset successfully created.
Shape of dataset: torch.Size([1200, 2])
Shape of labels: torch.Size([1200])
First 5 samples:
tensor([[-3.3426, -1.8364],
        [ 3.3833, -2.4394],
        [-3.3060, -2.2763],
        [ 3.2458, -2.8907],
        [ 3.4905, -2.1368]])
Corresponding labels:
tensor([1, 2, 1, 2, 2])
1
(1200, 2)
Toy Data
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/guides_user_guide_2_1.png" src="../_images/guides_user_guide_2_1.png" />
</div>
</div>
</section>
<section id="Model-Configuration">
<h2>Model Configuration<a class="headerlink" href="#Model-Configuration" title="Link to this heading">¶</a></h2>
<p>The circuits you create with this library are modular.</p>
<p>All modules share the same base structure. Each module is defined by its number of output features and output channels. You can think of output features as the number of nodes with different scopes in one layer. You can think of output channels as how many times a node with the same scope is repeated in a layer. This structure lets you define simple nodes (with a shape of (1, 1)), node vectors along the feature (N, 1) or channel (1, M) dimension, or full leaf layers (N, M). In many cases, using
layers instead of single nodes is much faster and more memory-efficient.</p>
<p>Each module also has an input attribute that points to its input module. This lets you stack modules together in any order.</p>
<p>Below, we will build a simple Sum-Product Network by stacking leaf, product, and sum layers.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">spflow.modules.leaves</span><span class="w"> </span><span class="kn">import</span> <span class="n">Normal</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">spflow.modules.sums</span><span class="w"> </span><span class="kn">import</span> <span class="n">Sum</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">spflow.modules.products</span><span class="w"> </span><span class="kn">import</span> <span class="n">Product</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">spflow.meta.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">Scope</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">IPython.display</span><span class="w"> </span><span class="kn">import</span> <span class="n">display</span><span class="p">,</span> <span class="n">Image</span>

<span class="n">scope</span> <span class="o">=</span> <span class="n">Scope</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="n">leaf_layer</span> <span class="o">=</span> <span class="n">Normal</span><span class="p">(</span><span class="n">scope</span><span class="o">=</span><span class="n">scope</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
<span class="n">product_layer</span> <span class="o">=</span> <span class="n">Product</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">leaf_layer</span><span class="p">)</span>
<span class="n">spn</span> <span class="o">=</span> <span class="n">Sum</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">product_layer</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">spn</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Sum(
  D=1, C=1, R=1, weights=(1, 6, 1, 1)
  (inputs): Product(
    D=1, C=6, R=1
    (inputs): Normal(D=2, C=6, R=1)
  )
)
</pre></div></div>
</div>
<p>Below is a visualization of the SPN defined above. The number of output channels of a sum or leaf layer is equivalent to the number of nodes in that layer. The number of nodes in a product layer is derived from the number of nodes in its input.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">display</span><span class="p">(</span><span class="n">Image</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="s1">&#39;StandardSPN.png&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/guides_user_guide_6_0.png" src="../_images/guides_user_guide_6_0.png" />
</div>
</div>
<p>Next, we can train the SPN, for example, using gradient descent. The library already provides a method for training an SPN with gradient descent. To do this, simply pass the module you want to train and the training parameters such as the number of epochs, learning rate, etc.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">spflow.learn</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_gradient_descent</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">TensorDataset</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">logging</span>

<span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span>
    <span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">,</span>
    <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;</span><span class="si">%(asctime)s</span><span class="s2"> [</span><span class="si">%(levelname)s</span><span class="s2">] </span><span class="si">%(name)s</span><span class="s2">: </span><span class="si">%(message)s</span><span class="s2">&quot;</span>
<span class="p">)</span>

<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">train_gradient_descent</span><span class="p">(</span><span class="n">spn</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2025-12-30 07:07:37,232 [INFO] spflow.learn.gradient_descent: Epoch [0/10]: Loss: 2.8904616832733154
2025-12-30 07:07:37,338 [INFO] spflow.learn.gradient_descent: Epoch [1/10]: Loss: 2.9267611503601074
2025-12-30 07:07:37,444 [INFO] spflow.learn.gradient_descent: Epoch [2/10]: Loss: 2.972346782684326
2025-12-30 07:07:37,551 [INFO] spflow.learn.gradient_descent: Epoch [3/10]: Loss: 2.9362776279449463
2025-12-30 07:07:37,658 [INFO] spflow.learn.gradient_descent: Epoch [4/10]: Loss: 2.951829433441162
2025-12-30 07:07:37,765 [INFO] spflow.learn.gradient_descent: Epoch [5/10]: Loss: 2.846937656402588
2025-12-30 07:07:37,871 [INFO] spflow.learn.gradient_descent: Epoch [6/10]: Loss: 2.841270685195923
2025-12-30 07:07:37,976 [INFO] spflow.learn.gradient_descent: Epoch [7/10]: Loss: 2.840902090072632
2025-12-30 07:07:38,082 [INFO] spflow.learn.gradient_descent: Epoch [8/10]: Loss: 2.8424298763275146
2025-12-30 07:07:38,188 [INFO] spflow.learn.gradient_descent: Epoch [9/10]: Loss: 2.8436360359191895
</pre></div></div>
</div>
<p>Once the SPN is trained, we can perform queries such as inference and sampling. SPFlow uses internal dispatching so that a single query function can work across all module types. For example, the log_likelihood method shown below can be used for every SPN model encountered throughout this guide.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ll</span> <span class="o">=</span> <span class="n">spn</span><span class="o">.</span><span class="n">log_likelihood</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="n">ll</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
tensor([[[[-2.0002]]],


        [[[-1.9763]]],


        [[[-2.1800]]],


        ...,


        [[[-3.7796]]],


        [[[-2.0846]]],


        [[[-2.9593]]]], grad_fn=&lt;ViewBackward0&gt;)
</pre></div></div>
</div>
<p>Finally, we can visualize the training results on our toy dataset.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><br/><br/><span></span><span class="n">data_np</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>


<span class="k">def</span><span class="w"> </span><span class="nf">plot_contour</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">spn</span><span class="p">):</span>
    <span class="c1"># Define the boundaries of the plot with a small padding</span>
    <span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span> <span class="o">=</span> <span class="n">data_np</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">data_np</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span> <span class="o">=</span> <span class="n">data_np</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">data_np</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span>

    <span class="c1"># Create a grid of points</span>
    <span class="n">grid_resolution</span> <span class="o">=</span> <span class="mi">200</span>
    <span class="n">xx</span><span class="p">,</span> <span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">grid_resolution</span><span class="p">),</span>
                         <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span><span class="p">,</span> <span class="n">grid_resolution</span><span class="p">))</span>

    <span class="c1"># Stack the grid points into a format our function can accept: [n_points, 2]</span>
    <span class="n">grid_points</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xx</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">yy</span><span class="o">.</span><span class="n">ravel</span><span class="p">()],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">ll</span> <span class="o">=</span> <span class="n">spn</span><span class="o">.</span><span class="n">log_likelihood</span><span class="p">(</span><span class="n">grid_points</span><span class="p">)</span>
    <span class="c1"># Reshape the LL values to match the grid shape for plotting</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">ll</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="c1"># --- 6. Visualize the Data and Log-Likelihood Contours ---</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>

    <span class="c1"># Plot the filled contour map of the log-likelihood</span>
    <span class="c1"># Higher values (brighter colors) mean the model thinks data is more likely there</span>
    <span class="n">contour</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>

    <span class="c1"># Add a color bar to show the LL scale</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">contour</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Log-Likelihood $LL(\mathbf</span><span class="si">{x}</span><span class="s1">)$&#39;</span><span class="p">)</span>

    <span class="c1"># Overlay the scatter plot of the actual data points</span>
    <span class="c1"># We make them semi-transparent and small to see the density and contours</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">data_np</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">data_np</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">)</span>

    <span class="c1"># Add titles and labels</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;SPN Log-Likelihood Contours and Data&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Feature 1 (x-axis)&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Feature 2 (y-axis)&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">)</span>  <span class="c1"># Ensures the scaling is the same on both axes</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="n">plot_contour</span><span class="p">(</span><span class="n">data_np</span><span class="p">,</span> <span class="n">spn</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/guides_user_guide_12_0.png" src="../_images/guides_user_guide_12_0.png" />
</div>
</div>
</section>
<section id="Temporary-Method-Replacement">
<h2>Temporary Method Replacement<a class="headerlink" href="#Temporary-Method-Replacement" title="Link to this heading">¶</a></h2>
<p>SPFlow supports temporarily substituting module methods. For example, you can replace the sum operation in <code class="docutils literal notranslate"><span class="pre">Sum</span></code> with a custom implementation for a single call graph.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">spflow.modules.sums</span><span class="w"> </span><span class="kn">import</span> <span class="n">Sum</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">spflow.modules.products</span><span class="w"> </span><span class="kn">import</span> <span class="n">Product</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">spflow.modules.leaves</span><span class="w"> </span><span class="kn">import</span> <span class="n">Normal</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">spflow.meta</span><span class="w"> </span><span class="kn">import</span> <span class="n">Scope</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">spflow.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">replace</span>

<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Create a probabilistic circuit: Product(Sum(Product(Normal)))</span>
<span class="n">scope</span> <span class="o">=</span> <span class="n">Scope</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">normal</span> <span class="o">=</span> <span class="n">Normal</span><span class="p">(</span><span class="n">scope</span><span class="o">=</span><span class="n">scope</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">inner_product</span> <span class="o">=</span> <span class="n">Product</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">normal</span><span class="p">)</span>
<span class="n">sum_module</span> <span class="o">=</span> <span class="n">Sum</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inner_product</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">root_product</span> <span class="o">=</span> <span class="n">Product</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">sum_module</span><span class="p">)</span>

<span class="c1"># Create test data</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="c1"># Normal inference</span>
<span class="n">log_likelihood_original</span> <span class="o">=</span> <span class="n">root_product</span><span class="o">.</span><span class="n">log_likelihood</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Original log-likelihood: </span><span class="si">{</span><span class="n">log_likelihood_original</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Define a custom log_likelihood for Sum modules</span>
<span class="k">def</span><span class="w"> </span><span class="nf">max_ll</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">ll</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">log_likelihood</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="n">cache</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">weighted_lls</span> <span class="o">=</span> <span class="n">ll</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_weights</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">weighted_lls</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sum_dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># Temporarily replace Sum.log_likelihood with custom implementation</span>
<span class="k">with</span> <span class="n">replace</span><span class="p">(</span><span class="n">Sum</span><span class="o">.</span><span class="n">log_likelihood</span><span class="p">,</span> <span class="n">max_ll</span><span class="p">):</span>
    <span class="n">log_likelihood_custom</span> <span class="o">=</span> <span class="n">root_product</span><span class="o">.</span><span class="n">log_likelihood</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Custom log-likelihood:   </span><span class="si">{</span><span class="n">log_likelihood_custom</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Original method is automatically restored</span>
<span class="n">log_likelihood_restored</span> <span class="o">=</span> <span class="n">root_product</span><span class="o">.</span><span class="n">log_likelihood</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Restored log-likelihood: </span><span class="si">{</span><span class="n">log_likelihood_restored</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<br/><br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Original log-likelihood: tensor([-1.2842, -2.8750, -7.2442], grad_fn=&lt;ViewBackward0&gt;)
Custom log-likelihood:   tensor([-1.4334, -3.5256, -7.9031], grad_fn=&lt;ViewBackward0&gt;)
Restored log-likelihood: tensor([-1.2842, -2.8750, -7.2442], grad_fn=&lt;ViewBackward0&gt;)
</pre></div></div>
</div>
</section>
<section id="Automatic-Model-creation">
<h2>Automatic Model creation<a class="headerlink" href="#Automatic-Model-creation" title="Link to this heading">¶</a></h2>
<p>Besides creating an SPN manually by stacking layers, it is also possible to use algorithms to automatically construct the SPN architecture. This can make it easier to start using SPNs.</p>
<section id="Rat-SPN">
<h3>Rat-SPN<a class="headerlink" href="#Rat-SPN" title="Link to this heading">¶</a></h3>
<p>The Rat-SPN algorithm builds a deep network structure by recursively partitioning the features (variables) into random subsets and alternating between sum and product layers. Below, we set up a Rat-SPN by defining its structure and parameters.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">spflow.modules.rat.rat_spn</span><span class="w"> </span><span class="kn">import</span> <span class="n">RatSPN</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">spflow.modules.ops.split</span><span class="w"> </span><span class="kn">import</span> <span class="n">SplitMode</span>

<span class="n">depth</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">n_region_nodes</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">num_leaves</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">num_repetitions</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">n_root_nodes</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">num_feature</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">scope</span> <span class="o">=</span> <span class="n">Scope</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_feature</span><span class="p">)))</span>

<span class="n">rat_leaf_layer</span> <span class="o">=</span> <span class="n">Normal</span><span class="p">(</span><span class="n">scope</span><span class="o">=</span><span class="n">scope</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="n">num_leaves</span><span class="p">,</span> <span class="n">num_repetitions</span><span class="o">=</span><span class="n">num_repetitions</span><span class="p">)</span>
<span class="n">rat</span> <span class="o">=</span> <span class="n">RatSPN</span><span class="p">(</span>
    <span class="n">leaf_modules</span><span class="o">=</span><span class="p">[</span><span class="n">rat_leaf_layer</span><span class="p">],</span>
    <span class="n">n_root_nodes</span><span class="o">=</span><span class="n">n_root_nodes</span><span class="p">,</span>
    <span class="n">n_region_nodes</span><span class="o">=</span><span class="n">n_region_nodes</span><span class="p">,</span>
    <span class="n">num_repetitions</span><span class="o">=</span><span class="n">num_repetitions</span><span class="p">,</span>
    <span class="n">depth</span><span class="o">=</span><span class="n">depth</span><span class="p">,</span>
    <span class="n">outer_product</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">split_mode</span><span class="o">=</span><span class="n">SplitMode</span><span class="o">.</span><span class="n">consecutive</span><span class="p">(),</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">rat</span><span class="o">.</span><span class="n">to_str</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
RatSPN [D=1, C=1, R=2] → scope: 0-1
└─ RepetitionMixingLayer [D=1, C=1] [weights: (1, 1, 2)] → scope: 0-1
   └─ Sum [D=1, C=1] [weights: (1, 4, 1, 2)] → scope: 0-1
      └─ OuterProduct [D=1, C=4] → scope: 0-1
         └─ SplitConsecutive [D=2, C=2] → scope: 0-1
            └─ Factorize [D=2, C=2] → scope: 0-1
               └─ Normal [D=2, C=2] → scope: 0-1
</pre></div></div>
</div>
<p>Here is a visualization of the architecture we just created.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">display</span><span class="p">(</span><span class="n">Image</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="s1">&#39;Rat_SPN.png&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/guides_user_guide_19_0.png" src="../_images/guides_user_guide_19_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ll</span> <span class="o">=</span> <span class="n">rat</span><span class="o">.</span><span class="n">log_likelihood</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="n">ll</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
tensor([[[[-10.6569]]],


        [[[-13.9143]]],


        [[[-11.5026]]],


        ...,


        [[[ -5.9139]]],


        [[[ -8.2588]]],


        [[[ -6.3513]]]], grad_fn=&lt;ViewBackward0&gt;)
</pre></div></div>
</div>
<p>We can again train this model using the provided gradient descent method.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_gradient_descent</span><span class="p">(</span><span class="n">rat</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>To verify that the training worked properly, we can visualize the log-likelihoods of the trained model.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data_np</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">plot_contour</span><span class="p">(</span><span class="n">data_np</span><span class="p">,</span> <span class="n">rat</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/guides_user_guide_24_0.png" src="../_images/guides_user_guide_24_0.png" />
</div>
</div>
<p>Of course, computing log-likelihoods is not the only thing the model can do. Below is a visualization of samples drawn from the trained Rat-SPN.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">samples</span> <span class="o">=</span> <span class="n">spn</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">1500</span><span class="p">)</span>
<span class="n">plot_scatter</span><span class="p">([</span><span class="n">data_np</span><span class="p">,</span> <span class="n">samples</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Generated 2D Toy Dataset&#39;</span><span class="p">,</span> <span class="n">label_list</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Original Data&#39;</span><span class="p">,</span> <span class="s1">&#39;Samples&#39;</span><span class="p">])</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
2
(1200, 2)
Original Data
2
torch.Size([1500, 2])
Samples
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/guides_user_guide_26_1.png" src="../_images/guides_user_guide_26_1.png" />
</div>
</div>
<p>Up to now, we have focused only on generation, without considering the labels of the training instances. Next, we will train a second Rat-SPN for classification.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">logging</span>

<span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span>
    <span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">,</span>
    <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;</span><span class="si">%(asctime)s</span><span class="s2"> [</span><span class="si">%(levelname)s</span><span class="s2">] </span><span class="si">%(name)s</span><span class="s2">: </span><span class="si">%(message)s</span><span class="s2">&quot;</span>
<span class="p">)</span>

<span class="n">depth</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">n_region_nodes</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">num_leaves</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">num_repetitions</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">n_root_nodes</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">num_feature</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">scope</span> <span class="o">=</span> <span class="n">Scope</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_feature</span><span class="p">)))</span>

<span class="n">rat_leaf_layer</span> <span class="o">=</span> <span class="n">Normal</span><span class="p">(</span><span class="n">scope</span><span class="o">=</span><span class="n">scope</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="n">num_leaves</span><span class="p">,</span> <span class="n">num_repetitions</span><span class="o">=</span><span class="n">num_repetitions</span><span class="p">)</span>
<span class="n">rat_class</span> <span class="o">=</span> <span class="n">RatSPN</span><span class="p">(</span>
    <span class="n">leaf_modules</span><span class="o">=</span><span class="p">[</span><span class="n">rat_leaf_layer</span><span class="p">],</span>
    <span class="n">n_root_nodes</span><span class="o">=</span><span class="n">n_root_nodes</span><span class="p">,</span>
    <span class="n">n_region_nodes</span><span class="o">=</span><span class="n">n_region_nodes</span><span class="p">,</span>
    <span class="n">num_repetitions</span><span class="o">=</span><span class="n">num_repetitions</span><span class="p">,</span>
    <span class="n">depth</span><span class="o">=</span><span class="n">depth</span><span class="p">,</span>
    <span class="n">outer_product</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">split_mode</span><span class="o">=</span><span class="n">SplitMode</span><span class="o">.</span><span class="n">consecutive</span><span class="p">(),</span>
<span class="p">)</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">clone</span><span class="p">(),</span> <span class="n">labels</span><span class="o">.</span><span class="n">clone</span><span class="p">())</span>

<span class="n">dataloader_with_labels</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="n">train_gradient_descent</span><span class="p">(</span><span class="n">rat_class</span><span class="p">,</span> <span class="n">dataloader_with_labels</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">is_classification</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                       <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<br/><br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2025-12-30 07:07:42,230 [INFO] spflow.learn.gradient_descent: Epoch [0/100]: Loss: 2.004916191101074
2025-12-30 07:07:42,517 [INFO] spflow.learn.gradient_descent: Epoch [1/100]: Loss: 1.9983692169189453
2025-12-30 07:07:42,804 [INFO] spflow.learn.gradient_descent: Epoch [2/100]: Loss: 1.9854066371917725
2025-12-30 07:07:43,092 [INFO] spflow.learn.gradient_descent: Epoch [3/100]: Loss: 2.00046968460083
2025-12-30 07:07:43,380 [INFO] spflow.learn.gradient_descent: Epoch [4/100]: Loss: 2.003180503845215
2025-12-30 07:07:43,666 [INFO] spflow.learn.gradient_descent: Epoch [5/100]: Loss: 2.0203356742858887
2025-12-30 07:07:43,956 [INFO] spflow.learn.gradient_descent: Epoch [6/100]: Loss: 2.0262837409973145
2025-12-30 07:07:44,243 [INFO] spflow.learn.gradient_descent: Epoch [7/100]: Loss: 2.0263619422912598
2025-12-30 07:07:44,529 [INFO] spflow.learn.gradient_descent: Epoch [8/100]: Loss: 2.019497871398926
2025-12-30 07:07:44,818 [INFO] spflow.learn.gradient_descent: Epoch [9/100]: Loss: 2.01088809967041
2025-12-30 07:07:45,112 [INFO] spflow.learn.gradient_descent: Epoch [10/100]: Loss: 2.003439426422119
2025-12-30 07:07:45,407 [INFO] spflow.learn.gradient_descent: Epoch [11/100]: Loss: 1.9976564645767212
2025-12-30 07:07:45,704 [INFO] spflow.learn.gradient_descent: Epoch [12/100]: Loss: 1.9932737350463867
2025-12-30 07:07:45,993 [INFO] spflow.learn.gradient_descent: Epoch [13/100]: Loss: 1.9899115562438965
2025-12-30 07:07:46,280 [INFO] spflow.learn.gradient_descent: Epoch [14/100]: Loss: 1.9872711896896362
2025-12-30 07:07:46,568 [INFO] spflow.learn.gradient_descent: Epoch [15/100]: Loss: 1.9851515293121338
2025-12-30 07:07:46,864 [INFO] spflow.learn.gradient_descent: Epoch [16/100]: Loss: 1.9834233522415161
2025-12-30 07:07:47,167 [INFO] spflow.learn.gradient_descent: Epoch [17/100]: Loss: 1.98200523853302
2025-12-30 07:07:47,462 [INFO] spflow.learn.gradient_descent: Epoch [18/100]: Loss: 1.9808424711227417
2025-12-30 07:07:47,756 [INFO] spflow.learn.gradient_descent: Epoch [19/100]: Loss: 1.9799026250839233
2025-12-30 07:07:48,048 [INFO] spflow.learn.gradient_descent: Epoch [20/100]: Loss: 1.9791715145111084
2025-12-30 07:07:48,341 [INFO] spflow.learn.gradient_descent: Epoch [21/100]: Loss: 1.9786738157272339
2025-12-30 07:07:48,632 [INFO] spflow.learn.gradient_descent: Epoch [22/100]: Loss: 1.9785351753234863
2025-12-30 07:07:48,926 [INFO] spflow.learn.gradient_descent: Epoch [23/100]: Loss: 1.9792839288711548
2025-12-30 07:07:49,215 [INFO] spflow.learn.gradient_descent: Epoch [24/100]: Loss: 1.9828391075134277
2025-12-30 07:07:49,503 [INFO] spflow.learn.gradient_descent: Epoch [25/100]: Loss: 1.9871528148651123
2025-12-30 07:07:49,790 [INFO] spflow.learn.gradient_descent: Epoch [26/100]: Loss: 1.9882378578186035
2025-12-30 07:07:50,079 [INFO] spflow.learn.gradient_descent: Epoch [27/100]: Loss: 1.9883610010147095
2025-12-30 07:07:50,369 [INFO] spflow.learn.gradient_descent: Epoch [28/100]: Loss: 1.9880238771438599
2025-12-30 07:07:50,659 [INFO] spflow.learn.gradient_descent: Epoch [29/100]: Loss: 1.9874569177627563
2025-12-30 07:07:50,950 [INFO] spflow.learn.gradient_descent: Epoch [30/100]: Loss: 1.9867730140686035
2025-12-30 07:07:51,242 [INFO] spflow.learn.gradient_descent: Epoch [31/100]: Loss: 1.9860366582870483
2025-12-30 07:07:51,534 [INFO] spflow.learn.gradient_descent: Epoch [32/100]: Loss: 1.9852875471115112
2025-12-30 07:07:51,822 [INFO] spflow.learn.gradient_descent: Epoch [33/100]: Loss: 1.9845486879348755
2025-12-30 07:07:52,111 [INFO] spflow.learn.gradient_descent: Epoch [34/100]: Loss: 1.9838343858718872
2025-12-30 07:07:52,402 [INFO] spflow.learn.gradient_descent: Epoch [35/100]: Loss: 1.983153223991394
2025-12-30 07:07:52,694 [INFO] spflow.learn.gradient_descent: Epoch [36/100]: Loss: 1.982508659362793
2025-12-30 07:07:52,984 [INFO] spflow.learn.gradient_descent: Epoch [37/100]: Loss: 1.9819039106369019
2025-12-30 07:07:53,274 [INFO] spflow.learn.gradient_descent: Epoch [38/100]: Loss: 1.9813389778137207
2025-12-30 07:07:53,587 [INFO] spflow.learn.gradient_descent: Epoch [39/100]: Loss: 1.980811357498169
2025-12-30 07:07:53,879 [INFO] spflow.learn.gradient_descent: Epoch [40/100]: Loss: 1.9803215265274048
2025-12-30 07:07:54,168 [INFO] spflow.learn.gradient_descent: Epoch [41/100]: Loss: 1.9798669815063477
2025-12-30 07:07:54,455 [INFO] spflow.learn.gradient_descent: Epoch [42/100]: Loss: 1.9794455766677856
2025-12-30 07:07:54,742 [INFO] spflow.learn.gradient_descent: Epoch [43/100]: Loss: 1.9790539741516113
2025-12-30 07:07:55,030 [INFO] spflow.learn.gradient_descent: Epoch [44/100]: Loss: 1.9786913394927979
2025-12-30 07:07:55,319 [INFO] spflow.learn.gradient_descent: Epoch [45/100]: Loss: 1.9783556461334229
2025-12-30 07:07:55,606 [INFO] spflow.learn.gradient_descent: Epoch [46/100]: Loss: 1.9780433177947998
2025-12-30 07:07:55,892 [INFO] spflow.learn.gradient_descent: Epoch [47/100]: Loss: 1.9777541160583496
2025-12-30 07:07:56,179 [INFO] spflow.learn.gradient_descent: Epoch [48/100]: Loss: 1.9774855375289917
2025-12-30 07:07:56,466 [INFO] spflow.learn.gradient_descent: Epoch [49/100]: Loss: 1.9772359132766724
2025-12-30 07:07:56,755 [INFO] spflow.learn.gradient_descent: Epoch [50/100]: Loss: 1.8436698913574219
2025-12-30 07:07:57,046 [INFO] spflow.learn.gradient_descent: Epoch [51/100]: Loss: 1.8269050121307373
2025-12-30 07:07:57,335 [INFO] spflow.learn.gradient_descent: Epoch [52/100]: Loss: 1.8231121301651
2025-12-30 07:07:57,624 [INFO] spflow.learn.gradient_descent: Epoch [53/100]: Loss: 1.8216547966003418
2025-12-30 07:07:57,911 [INFO] spflow.learn.gradient_descent: Epoch [54/100]: Loss: 1.820709466934204
2025-12-30 07:07:58,199 [INFO] spflow.learn.gradient_descent: Epoch [55/100]: Loss: 1.819972276687622
2025-12-30 07:07:58,485 [INFO] spflow.learn.gradient_descent: Epoch [56/100]: Loss: 1.8193639516830444
2025-12-30 07:07:58,773 [INFO] spflow.learn.gradient_descent: Epoch [57/100]: Loss: 1.8188468217849731
2025-12-30 07:07:59,060 [INFO] spflow.learn.gradient_descent: Epoch [58/100]: Loss: 1.8184024095535278
2025-12-30 07:07:59,347 [INFO] spflow.learn.gradient_descent: Epoch [59/100]: Loss: 1.818011999130249
2025-12-30 07:07:59,636 [INFO] spflow.learn.gradient_descent: Epoch [60/100]: Loss: 1.8176655769348145
2025-12-30 07:07:59,924 [INFO] spflow.learn.gradient_descent: Epoch [61/100]: Loss: 1.817354440689087
2025-12-30 07:08:00,214 [INFO] spflow.learn.gradient_descent: Epoch [62/100]: Loss: 1.8170727491378784
2025-12-30 07:08:00,500 [INFO] spflow.learn.gradient_descent: Epoch [63/100]: Loss: 1.8168137073516846
2025-12-30 07:08:00,787 [INFO] spflow.learn.gradient_descent: Epoch [64/100]: Loss: 1.8165779113769531
2025-12-30 07:08:01,074 [INFO] spflow.learn.gradient_descent: Epoch [65/100]: Loss: 1.8163585662841797
2025-12-30 07:08:01,362 [INFO] spflow.learn.gradient_descent: Epoch [66/100]: Loss: 1.8161550760269165
2025-12-30 07:08:01,649 [INFO] spflow.learn.gradient_descent: Epoch [67/100]: Loss: 1.8159652948379517
2025-12-30 07:08:01,936 [INFO] spflow.learn.gradient_descent: Epoch [68/100]: Loss: 1.8157873153686523
2025-12-30 07:08:02,223 [INFO] spflow.learn.gradient_descent: Epoch [69/100]: Loss: 1.8156182765960693
2025-12-30 07:08:02,511 [INFO] spflow.learn.gradient_descent: Epoch [70/100]: Loss: 1.8154606819152832
2025-12-30 07:08:02,796 [INFO] spflow.learn.gradient_descent: Epoch [71/100]: Loss: 1.8153102397918701
2025-12-30 07:08:03,083 [INFO] spflow.learn.gradient_descent: Epoch [72/100]: Loss: 1.8151687383651733
2025-12-30 07:08:03,371 [INFO] spflow.learn.gradient_descent: Epoch [73/100]: Loss: 1.8150336742401123
2025-12-30 07:08:03,662 [INFO] spflow.learn.gradient_descent: Epoch [74/100]: Loss: 1.814906358718872
2025-12-30 07:08:03,952 [INFO] spflow.learn.gradient_descent: Epoch [75/100]: Loss: 1.815582036972046
2025-12-30 07:08:04,237 [INFO] spflow.learn.gradient_descent: Epoch [76/100]: Loss: 1.8179190158843994
2025-12-30 07:08:04,526 [INFO] spflow.learn.gradient_descent: Epoch [77/100]: Loss: 1.8199260234832764
2025-12-30 07:08:04,814 [INFO] spflow.learn.gradient_descent: Epoch [78/100]: Loss: 1.8215827941894531
2025-12-30 07:08:05,102 [INFO] spflow.learn.gradient_descent: Epoch [79/100]: Loss: 1.822925329208374
2025-12-30 07:08:05,391 [INFO] spflow.learn.gradient_descent: Epoch [80/100]: Loss: 1.8240020275115967
2025-12-30 07:08:05,684 [INFO] spflow.learn.gradient_descent: Epoch [81/100]: Loss: 1.8248565196990967
2025-12-30 07:08:05,975 [INFO] spflow.learn.gradient_descent: Epoch [82/100]: Loss: 1.8255341053009033
2025-12-30 07:08:06,267 [INFO] spflow.learn.gradient_descent: Epoch [83/100]: Loss: 1.82606840133667
2025-12-30 07:08:06,558 [INFO] spflow.learn.gradient_descent: Epoch [84/100]: Loss: 1.826488733291626
2025-12-30 07:08:06,850 [INFO] spflow.learn.gradient_descent: Epoch [85/100]: Loss: 1.826817512512207
2025-12-30 07:08:07,143 [INFO] spflow.learn.gradient_descent: Epoch [86/100]: Loss: 1.827073335647583
2025-12-30 07:08:07,437 [INFO] spflow.learn.gradient_descent: Epoch [87/100]: Loss: 1.8272745609283447
2025-12-30 07:08:07,730 [INFO] spflow.learn.gradient_descent: Epoch [88/100]: Loss: 1.8274303674697876
2025-12-30 07:08:08,022 [INFO] spflow.learn.gradient_descent: Epoch [89/100]: Loss: 1.8275498151779175
2025-12-30 07:08:08,314 [INFO] spflow.learn.gradient_descent: Epoch [90/100]: Loss: 1.8276420831680298
2025-12-30 07:08:08,606 [INFO] spflow.learn.gradient_descent: Epoch [91/100]: Loss: 1.8277121782302856
2025-12-30 07:08:08,897 [INFO] spflow.learn.gradient_descent: Epoch [92/100]: Loss: 1.8277643918991089
2025-12-30 07:08:09,188 [INFO] spflow.learn.gradient_descent: Epoch [93/100]: Loss: 1.8278027772903442
2025-12-30 07:08:09,479 [INFO] spflow.learn.gradient_descent: Epoch [94/100]: Loss: 1.8278287649154663
2025-12-30 07:08:09,773 [INFO] spflow.learn.gradient_descent: Epoch [95/100]: Loss: 1.8278459310531616
2025-12-30 07:08:10,063 [INFO] spflow.learn.gradient_descent: Epoch [96/100]: Loss: 1.8278549909591675
2025-12-30 07:08:10,355 [INFO] spflow.learn.gradient_descent: Epoch [97/100]: Loss: 1.8278597593307495
2025-12-30 07:08:10,647 [INFO] spflow.learn.gradient_descent: Epoch [98/100]: Loss: 1.8278602361679077
2025-12-30 07:08:10,938 [INFO] spflow.learn.gradient_descent: Epoch [99/100]: Loss: 1.8278555870056152
</pre></div></div>
</div>
<p>With this SPN, we can now draw samples based on its labels. Therefore, we use a sampling context. This sampling context can be passed to any sampling method. With the context, you can explicitly define from which output channel you want to sample or, for example, provide evidence. This allows advanced control over the sampling routine. In this case, the root layer has three output channels which correspond to the three classes. So being able to define from which output channel we want to sample
means being able to choose from which class we want to sample.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">spflow.utils.sampling_context</span><span class="w"> </span><span class="kn">import</span> <span class="n">SamplingContext</span>

<span class="n">out_features</span> <span class="o">=</span> <span class="n">rat</span><span class="o">.</span><span class="n">out_shape</span><span class="o">.</span><span class="n">features</span>
<span class="n">num_features</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">evidence</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="mi">200</span><span class="p">,</span> <span class="n">num_features</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
<span class="n">channel_index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="mi">200</span><span class="p">,</span> <span class="n">out_features</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="mi">200</span><span class="p">,</span> <span class="n">out_features</span><span class="p">),</span> <span class="kc">True</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
<span class="n">sampling_ctx</span> <span class="o">=</span> <span class="n">SamplingContext</span><span class="p">(</span><span class="n">channel_index</span><span class="o">=</span><span class="n">channel_index</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">)</span>
<span class="n">samples_class0</span> <span class="o">=</span> <span class="n">rat_class</span><span class="o">.</span><span class="n">root_node</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">evidence</span><span class="p">,</span> <span class="n">sampling_ctx</span><span class="o">=</span><span class="n">sampling_ctx</span><span class="p">)</span>

<span class="n">evidence</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="mi">400</span><span class="p">,</span> <span class="n">num_features</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
<span class="n">channel_index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="mi">400</span><span class="p">,</span> <span class="n">out_features</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="mi">400</span><span class="p">,</span> <span class="n">out_features</span><span class="p">),</span> <span class="kc">True</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
<span class="n">sampling_ctx</span> <span class="o">=</span> <span class="n">SamplingContext</span><span class="p">(</span><span class="n">channel_index</span><span class="o">=</span><span class="n">channel_index</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">)</span>
<span class="n">samples_class1</span> <span class="o">=</span> <span class="n">rat_class</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">evidence</span><span class="p">,</span> <span class="n">sampling_ctx</span><span class="o">=</span><span class="n">sampling_ctx</span><span class="p">)</span>

<span class="n">evidence</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="mi">600</span><span class="p">,</span> <span class="n">num_features</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
<span class="n">channel_index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="mi">600</span><span class="p">,</span> <span class="n">out_features</span><span class="p">),</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="mi">600</span><span class="p">,</span> <span class="n">out_features</span><span class="p">),</span> <span class="kc">True</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
<span class="n">sampling_ctx</span> <span class="o">=</span> <span class="n">SamplingContext</span><span class="p">(</span><span class="n">channel_index</span><span class="o">=</span><span class="n">channel_index</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">)</span>
<span class="n">samples_class2</span> <span class="o">=</span> <span class="n">rat_class</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">evidence</span><span class="p">,</span> <span class="n">sampling_ctx</span><span class="o">=</span><span class="n">sampling_ctx</span><span class="p">)</span>

<span class="n">plot_scatter</span><span class="p">([</span><span class="n">data_np</span><span class="p">,</span> <span class="n">samples_class0</span><span class="p">,</span> <span class="n">samples_class1</span><span class="p">,</span> <span class="n">samples_class2</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Class-Conditional Samples&#39;</span><span class="p">,</span>
             <span class="n">label_list</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Original Data&#39;</span><span class="p">,</span> <span class="s1">&#39;Samples Class 0&#39;</span><span class="p">,</span> <span class="s1">&#39;Samples Class 1&#39;</span><span class="p">,</span> <span class="s1">&#39;Samples Class 2&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
4
(1200, 2)
Original Data
4
torch.Size([200, 2])
Samples Class 0
4
torch.Size([400, 2])
Samples Class 1
4
torch.Size([600, 2])
Samples Class 2
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/guides_user_guide_30_1.png" src="../_images/guides_user_guide_30_1.png" />
</div>
</div>
<p>However, the model can of course also be used for classification. As an example, we visualize the trained decision boundaries of our model</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="c1"># --- Assuming your dataset and labels are already created as above ---</span>

<span class="c1"># Let&#39;s assume you have an SPN model trained on this data:</span>
<span class="c1"># For example:</span>
<span class="c1"># spn = MySPNModel()</span>
<span class="c1"># spn.fit(dataset, labels)</span>

<span class="c1"># --- 1. Create a grid of points over the feature space ---</span>
<span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dataset</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dataset</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span>

<span class="n">xx</span><span class="p">,</span> <span class="n">yy</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="mi">300</span><span class="p">),</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span><span class="p">,</span> <span class="mi">300</span><span class="p">),</span>
    <span class="n">indexing</span><span class="o">=</span><span class="s1">&#39;xy&#39;</span>
<span class="p">)</span>
<span class="n">grid_points</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">xx</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">yy</span><span class="o">.</span><span class="n">flatten</span><span class="p">()],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># --- 2. Get SPN predictions (probabilities or class scores) ---</span>
<span class="c1"># Example: if your SPN returns class probabilities</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">rat_class</span><span class="o">.</span><span class="n">log_posterior</span><span class="p">(</span><span class="n">grid_points</span><span class="p">)</span>  <span class="c1"># shape: [N_grid, num_classes]</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">probs</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># --- 3. Reshape predictions to match the grid ---</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">preds</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># --- 4. Plot decision boundaries ---</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">means</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;viridis&quot;</span><span class="p">)</span>

<span class="c1"># Plot the original data</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">dataset</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">dataset</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;viridis&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;SPN Classification Boundaries&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;X₁&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;X₂&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/guides_user_guide_32_0.png" src="../_images/guides_user_guide_32_0.png" />
</div>
</div>
</section>
</section>
<section id="LearnSPN">
<h2>LearnSPN<a class="headerlink" href="#LearnSPN" title="Link to this heading">¶</a></h2>
<p>Instead of creating a random structure, we can also train the SPN structure using the LearnSPN.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">spflow.learn.learn_spn</span><span class="w"> </span><span class="kn">import</span> <span class="n">learn_spn</span>

<span class="n">scope</span> <span class="o">=</span> <span class="n">Scope</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">)))</span>
<span class="n">normal_layer</span> <span class="o">=</span> <span class="n">Normal</span><span class="p">(</span><span class="n">scope</span><span class="o">=</span><span class="n">scope</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">learn_spn</span> <span class="o">=</span> <span class="n">learn_spn</span><span class="p">(</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
    <span class="n">leaf_modules</span><span class="o">=</span><span class="n">normal_layer</span><span class="p">,</span>
    <span class="n">out_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">min_instances_slice</span><span class="o">=</span><span class="mi">70</span><span class="p">,</span>
    <span class="n">min_features_slice</span><span class="o">=</span><span class="mi">2</span>
<span class="p">)</span>
<span class="n">learn_spn</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/tmp/ipykernel_2487/568267606.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(dataset, dtype=torch.float32),
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Product(
  D=1, C=4, R=1
  (inputs): Cat(
    D=2, C=4, R=1, dim=1
    (inputs): ModuleList(
      (0-1): 2 x Normal(D=1, C=4, R=1)
    )
  )
)
</pre></div></div>
</div>
<p>The trained SPN can now be used just like any other module</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">learn_spn_samples</span> <span class="o">=</span> <span class="n">spn</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">1500</span><span class="p">)</span>

<span class="n">plot_scatter</span><span class="p">([</span><span class="n">data_np</span><span class="p">,</span> <span class="n">samples</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Generated 2D Toy Dataset&#39;</span><span class="p">,</span> <span class="n">label_list</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Original Data&#39;</span><span class="p">,</span> <span class="s1">&#39;Samples&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
2
(1200, 2)
Original Data
2
torch.Size([1500, 2])
Samples
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/guides_user_guide_36_1.png" src="../_images/guides_user_guide_36_1.png" />
</div>
</div>
</section>
<section id="Advanced-Queries">
<h2>Advanced Queries<a class="headerlink" href="#Advanced-Queries" title="Link to this heading">¶</a></h2>
<p>To showcase more advanced queries like conditional sampling and MPE (Most Probable Explanation) we take a look at a dataset with more features. Below, we load the digits dataset. This dataset contains 1797 8x8 images of digits 0 to 9.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn</span><span class="w"> </span><span class="kn">import</span> <span class="n">datasets</span>

<span class="c1"># Load the digits dataset</span>
<span class="n">digits</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_digits</span><span class="p">()</span>

<span class="c1"># Display the last digit</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">digits</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">gray_r</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s2">&quot;nearest&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">digits</span><span class="o">.</span><span class="n">data</span>  <span class="c1"># shape (1797, 64)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">digits</span><span class="o">.</span><span class="n">target</span>  <span class="c1"># shape (1797,)</span>

<span class="n">X_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">X_tensor</span><span class="p">,</span> <span class="n">y_tensor</span><span class="p">)</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">X_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_tensor</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">X_tensor</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/guides_user_guide_39_0.png" src="../_images/guides_user_guide_39_0.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
torch.Size([1797, 64])
tensor(0.) tensor(16.)
</pre></div></div>
</div>
<p>Again we create a Rat SPN, but this time we use a Binomial distribution for the leaf layer.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">spflow.modules.leaves</span><span class="w"> </span><span class="kn">import</span> <span class="n">Binomial</span>

<span class="n">depth</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">n_region_nodes</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">num_leaves</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">num_repetitions</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">n_root_nodes</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">num_feature</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">n</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">16</span><span class="p">)</span>  <span class="c1"># total count for binomial distribution</span>

<span class="n">scope</span> <span class="o">=</span> <span class="n">Scope</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_feature</span><span class="p">)))</span>

<span class="n">rat_leaf_layer</span> <span class="o">=</span> <span class="n">Binomial</span><span class="p">(</span><span class="n">scope</span><span class="o">=</span><span class="n">scope</span><span class="p">,</span> <span class="n">total_count</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="n">num_leaves</span><span class="p">,</span> <span class="n">num_repetitions</span><span class="o">=</span><span class="n">num_repetitions</span><span class="p">)</span>
<span class="n">rat</span> <span class="o">=</span> <span class="n">RatSPN</span><span class="p">(</span>
    <span class="n">leaf_modules</span><span class="o">=</span><span class="p">[</span><span class="n">rat_leaf_layer</span><span class="p">],</span>
    <span class="n">n_root_nodes</span><span class="o">=</span><span class="n">n_root_nodes</span><span class="p">,</span>
    <span class="n">n_region_nodes</span><span class="o">=</span><span class="n">n_region_nodes</span><span class="p">,</span>
    <span class="n">num_repetitions</span><span class="o">=</span><span class="n">num_repetitions</span><span class="p">,</span>
    <span class="n">depth</span><span class="o">=</span><span class="n">depth</span><span class="p">,</span>
    <span class="n">outer_product</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">split_mode</span><span class="o">=</span><span class="n">SplitMode</span><span class="o">.</span><span class="n">consecutive</span><span class="p">(),</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">rat</span><span class="o">.</span><span class="n">to_str</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
RatSPN [D=1, C=1, R=2] → scope: 0-63
└─ RepetitionMixingLayer [D=1, C=1] [weights: (1, 1, 2)] → scope: 0-63
   └─ Sum [D=1, C=1] [weights: (1, 25, 1, 2)] → scope: 0-63
      └─ OuterProduct [D=1, C=25] → scope: 0-63
         └─ SplitConsecutive [D=2, C=5] → scope: 0-63
            └─ Sum [D=2, C=5] [weights: (2, 25, 5, 2)] → scope: 0-63
               └─ OuterProduct [D=2, C=25] → scope: 0-63
                  └─ SplitConsecutive [D=4, C=5] → scope: 0-63
                     └─ Sum [D=4, C=5] [weights: (4, 25, 5, 2)] → scope: 0-63
                        └─ OuterProduct [D=4, C=25] → scope: 0-63
                           └─ SplitConsecutive [D=8, C=5] → scope: 0-63
                              └─ Factorize [D=8, C=5] → scope: 0-63
                                 └─ Binomial [D=64, C=5] → scope: 0-63
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_gradient_descent</span><span class="p">(</span><span class="n">rat</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Below is a visualization of some samples drawn from the Spn</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">samples</span> <span class="o">=</span> <span class="n">rat</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">samples</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">samples</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>  <span class="c1"># reshape back to 2D</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
torch.Size([5, 64])
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/guides_user_guide_44_1.png" src="../_images/guides_user_guide_44_1.png" />
</div>
</div>
<p>Now can show some more advanced queries. One of them is getting the MPE. It returns the most probable state of the probabilistic circuit. This is often helpful to generate more clear samples and a good indicator whether the model could learn the data or not, which is not always evident with regular samples.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mpe</span> <span class="o">=</span> <span class="n">rat</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">is_mpe</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">mpe</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/guides_user_guide_46_0.png" src="../_images/guides_user_guide_46_0.png" />
</div>
</div>
<p>And at last we want to sample, given some evidence. In this example, the lower half of the image is given, and we want to sample the upper half given the lower half. This time, instead of explicitly defining a sampling context, we use the sample_with_evidence method. The method allows the user to just input the evidence and let the library internally handle the creation of the sampling context. This becomes handy if you have evidence but not multiple channel to sample from.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">evidence</span> <span class="o">=</span> <span class="n">X_tensor</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">evidence</span><span class="p">[:</span><span class="mi">32</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nan</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">evidence</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">evidence</span> <span class="o">=</span> <span class="n">evidence</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">evidence</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">rat</span><span class="o">.</span><span class="n">sample_with_evidence</span><span class="p">(</span><span class="n">evidence</span><span class="o">=</span><span class="n">evidence</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">samples</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/guides_user_guide_48_0.png" src="../_images/guides_user_guide_48_0.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
torch.Size([1, 64])
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/guides_user_guide_48_2.png" src="../_images/guides_user_guide_48_2.png" />
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="dev_guide.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Developer Guide</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="../getting_started.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Getting Started</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2025, SPFlow Contributors
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">User Guide</a><ul>
<li><a class="reference internal" href="#Create-Toy-Dataset">Create Toy Dataset</a></li>
<li><a class="reference internal" href="#Model-Configuration">Model Configuration</a></li>
<li><a class="reference internal" href="#Temporary-Method-Replacement">Temporary Method Replacement</a></li>
<li><a class="reference internal" href="#Automatic-Model-creation">Automatic Model creation</a><ul>
<li><a class="reference internal" href="#Rat-SPN">Rat-SPN</a></li>
</ul>
</li>
<li><a class="reference internal" href="#LearnSPN">LearnSPN</a></li>
<li><a class="reference internal" href="#Advanced-Queries">Advanced Queries</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../_static/documentation_options.js?v=8d563738"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/furo.js?v=46bd48cc"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    </body>
</html>